replicaCount: 1

podDisruptionBudget:
  maxUnavailable: 1

updateStrategy:
  type: RollingUpdate

terminationGracePeriodSeconds: 30

image:
  repository: docker.elastic.co/logstash/logstash-oss
  tag: 7.1.1
  pullPolicy: IfNotPresent
  ## Add secrets manually via kubectl on kubernetes cluster and reference here
  #  pullSecrets:
  #    - name: "myKubernetesSecret"

service:
  type: ClusterIP
  # clusterIP: None
  # nodePort:
  # Set this to local, to preserve client source ip.  Default stripes out the source ip
  # externalTrafficPolicy: Local
  annotations: {}
    ## AWS example for use with LoadBalancer service type.
    # external-dns.alpha.kubernetes.io/hostname: logstash.cluster.local
    # service.beta.kubernetes.io/aws-load-balancer-cross-zone-load-balancing-enabled: "true"
    # service.beta.kubernetes.io/aws-load-balancer-internal: "true"
  ports:
    # syslog-udp:
    #   port: 1514
    #   targetPort: syslog-udp
    #   protocol: UDP
    # syslog-tcp:
    #   port: 1514
    #   targetPort: syslog-tcp
    #   protocol: TCP
    #beats:
    #  port: 5044
    #  targetPort: beats
    #  protocol: TCP
    http:
      port: 8080
      targetPort: http
      protocol: TCP
    #loadBalancerIP: 10.0.0.1
    #loadBalancerSourceRanges:
    #  - 192.168.0.1
ports:
  # - name: syslog-udp
  #   containerPort: 1514
  #   protocol: UDP
  # - name: syslog-tcp
  #   containerPort: 1514
  #   protocol: TCP
  # - name: beats
  #   containerPort: 5044
  #   protocol: TCP
  - name: http
    containerPort: 8080
    protocol: TCP

ingress:
  enabled: false
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  path: /
  hosts:
    - logstash.cluster.local
  tls: []
  #  - secretName: logstash-tls
  #    hosts:
  #      - logstash.cluster.local

# set java options like heap size
logstashJavaOpts: "-Xmx1g -Xms1g"

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #  cpu: 100m
  #  memory: 128Mi
  # requests:
  #  cpu: 100m
  #  memory: 128Mi

priorityClassName: ""

nodeSelector: {}

tolerations: []

securityContext:
  fsGroup: 1000
  runAsUser: 1000

affinity: {}
  # podAntiAffinity:
  #   requiredDuringSchedulingIgnoredDuringExecution:
  #     - topologyKey: "kubernetes.io/hostname"
  #       labelSelector:
  #         matchLabels:
  #           release: logstash

podAnnotations: {}
  # iam.amazonaws.com/role: "logstash-role"
  # prometheus.io/scrape: "true"
  # prometheus.io/path: "/metrics"
  # prometheus.io/port: "9198"

podLabels: {}
  # team: "developers"
  # service: "logstash"

extraEnv:
  - name: ELASTIC_USERNAME
    value: elastic
  - name: ELASTIC_PASSWORD
    valueFrom:
      secretKeyRef:
        name: insights-escluster-es-elastic-user
        key: elastic

extraInitContainers: []
  # - name: echo
  #   image: busybox
  #   imagePullPolicy: Always
  #   args:
  #     - echo
  #     - hello

podManagementPolicy: OrderedReady
 # can be OrderReady or Parallel
livenessProbe:
  httpGet:
    path: /
    port: monitor
  initialDelaySeconds: 60
  # periodSeconds: 30
  # timeoutSeconds: 30
  # failureThreshold: 6
  # successThreshold: 1

readinessProbe:
  httpGet:
    path: /
    port: monitor
  initialDelaySeconds: 60
  # periodSeconds: 30
  # timeoutSeconds: 30
  # failureThreshold: 6
  # successThreshold: 1

persistence:
  enabled: true
  ## logstash data Persistent Volume Storage Class
  ## If defined, storageClassName: <storageClass>
  ## If set to "-", storageClassName: "", which disables dynamic provisioning
  ## If undefined (the default) or set to null, no storageClassName spec is
  ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
  ##   GKE, AWS & OpenStack)
  ##
  storageClass: "gp2"
  accessMode: ReadWriteOnce
  size: 2Gi

volumeMounts:
  - name: data
    mountPath: /usr/share/logstash/data
  - name: patterns
    mountPath: /usr/share/logstash/patterns
  - name: files
    mountPath: /usr/share/logstash/files
  - name: pipeline
    mountPath: /usr/share/logstash/pipeline
  - name: es-http-certs
    readOnly: true
    mountPath: /etc/pki/client
  - name: es-transport-certs
    readOnly: true
    mountPath: /etc/pki/ca

volumes:
  # - name: tls
  #   secret:
  #     secretName: logstash-tls
  # - name: pipeline
  #   configMap:
  #     name: logstash-pipeline
  # - name: certs
  #   hostPath:
  #     path: /tmp
  - name: es-http-certs
    secret:
      secretName: insights-escluster-es-http-certs-public
  - name: es-transport-certs
    secret:
      secretName: insights-escluster-es-transport-certs-public

exporter:
  logstash:
    enabled: false
    image:
      repository: bonniernews/logstash_exporter
      tag: v0.1.2
      pullPolicy: IfNotPresent
    env: {}
    resources: {}
    path: /metrics
    port: 9198
    target:
      port: 9600
      path: /metrics
    livenessProbe:
      httpGet:
        path: /metrics
        port: ls-exporter
      periodSeconds: 15
      timeoutSeconds: 60
      failureThreshold: 8
      successThreshold: 1
    readinessProbe:
      httpGet:
        path: /metrics
        port: ls-exporter
      periodSeconds: 15
      timeoutSeconds: 60
      failureThreshold: 8
      successThreshold: 1

elasticsearch:
  host: 172.30.213.128                     #elasticsearch-client.nuodb.svc.cluster.local
  port: 9200

## ref: https://github.com/elastic/logstash-docker/blob/master/build/logstash/env2yaml/env2yaml.go
config:
  config.reload.automatic: "true"
  path.config: /usr/share/logstash/pipeline
  path.data: /usr/share/logstash/data

  ## ref: https://www.elastic.co/guide/en/logstash/current/persistent-queues.html
  queue.checkpoint.writes: 1
  queue.drain: "true"
  queue.max_bytes: 1gb  # disk capacity must be greater than the value of `queue.max_bytes`
  queue.type: persisted

  elastic_username: elastic


## Patterns for filters.
## Each YAML heredoc will become a separate pattern file.
patterns:
  # main: |-
  #   TESTING {"foo":.*}$

## Custom files that can be referenced by plugins.
## Each YAML heredoc will become located in the logstash home directory under
## the files subdirectory.
files:
  # logstash-template.json: |-
  #   {
  #     "order": 0,
  #     "version": 1,
  #     "index_patterns": [
  #       "logstash-*"
  #     ],
  #     "settings": {
  #       "index": {
  #         "refresh_interval": "5s"
  #       }
  #     },
  #     "mappings": {
  #       "doc": {
  #         "_meta": {
  #           "version": "1.0.0"
  #         },
  #         "enabled": false
  #       }
  #     },
  #     "aliases": {}
  #   }

## Custom binary files encoded as base64 string that can be referenced by plugins
## Each base64 encoded string is decoded & mounted as a file under logstash home directory under
## the files subdirectory.
binaryFiles: {}

## NOTE: To achieve multiple pipelines with this chart, current best practice
## is to maintain one pipeline per chart release. In this way configuration is
## simplified and pipelines are more isolated from one another.

inputs:
  main: |-
    input {
      http {
        host => "0.0.0.0"
        port => "8080"
        id => "sub_id"
        response_headers => {"Content-Type"=>"application/json"}
        codec => "json"
      }
    }

filters:
  main: |-
    filter {
      if ![timestamp] {
        drop { }
      }
      if ![sub_id] {
        drop { }
      }
      prune {
        blacklist_names => ["headers", "@version"]
      }

      # NuoMon
      if [NuoCA.plugin_name] == "NuoMon" {
        if ![NuoMon.NodeShortType] {
          if [NuoMon.NodeType] == "Transaction" {
            mutate { add_field => { "NuoMon.NodeShortType" => "TE" } }
          } else if [NuoMon.NodeType] == "Storage" {
            mutate { add_field => { "NuoMon.NodeShortType" => "SM" } }
          } else {
            mutate { add_field => { "NuoMon.NodeShortType" => "" } }
          }
        }
        if ![NuoMon.HostNameNuoTypeDBNamePID] {
          if [NuoMon.Hostname] {
            mutate {
              add_field => { "NuoMon.HostNameNuoTypeDBNamePID" => "%{NuoMon.Hostname}(%{NuoMon.Database}-%{NuoMon.NodeShortType}-%{NuoMon.ProcessId})" }
            }
          }
        }
      }
    }

outputs:
  main: |-
    output {
      if [NuoCA.plugin_name] == "NuoCALog" {
        elasticsearch {
          hosts => [ "https://${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}" ]
          ssl => true
          cacert => "/etc/pki/client/tls.crt"
          ssl_certificate_verification => false
          manage_template => false
          template_name => "ic_nuocalog_template"
          pipeline => "ic_nuocalog_pipeline"
          user => "${ELASTIC_USERNAME}"
          password => "${ELASTIC_PASSWORD}"
        }
      } else if [NuoCA.plugin_name] == "NuoAdminAgentLog" {
        elasticsearch {
          hosts => [ "https://${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}" ]
          ssl => true
          cacert => "/etc/pki/client/tls.crt"
          ssl_certificate_verification => false
          manage_template => false
          template_name => "ic_nuoadminagentlog_template"
          pipeline => "ic_nuoadminagentlog_pipeline"
          user => "${ELASTIC_USERNAME}"
          password => "${ELASTIC_PASSWORD}"
        }
      } else if [NuoCA.plugin_name] == "NuoAdminMon" {
        elasticsearch {
          hosts => [ "https://${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}" ]
          ssl => true
          cacert => "/etc/pki/client/tls.crt"
          ssl_certificate_verification => false
          manage_template => false
          template_name => "ic_nuoadminmon_template"
          pipeline => "ic_nuoadminmon_pipeline"
          user => "${ELASTIC_USERNAME}"
          password => "${ELASTIC_PASSWORD}"
        }
      } else if [NuoCA.plugin_name] == "NuoAdminMon2" {
        elasticsearch {
          hosts => [ "https://${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}" ]
          ssl => true
          cacert => "/etc/pki/client/tls.crt"
          ssl_certificate_verification => false
          manage_template => false
          template_name => "ic_nuoadminmon2_template"
          pipeline => "ic_nuoadminmon2_pipeline"
          user => "${ELASTIC_USERNAME}"
          password => "${ELASTIC_PASSWORD}"
        }
      } else if [NuoCA.plugin_name] == "NuoMon" {
        elasticsearch {
          hosts => [ "https://${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}" ]
          ssl => true
          cacert => "/etc/pki/client/tls.crt"
          ssl_certificate_verification => false
          manage_template => false
          template_name => "ic_nuomon_template"
          pipeline => "ic_nuomon_pipeline"
          user => "${ELASTIC_USERNAME}"
          password => "${ELASTIC_PASSWORD}"
        }
      } else if [NuoCA.plugin_name] == "ZBX" {
        elasticsearch {
          hosts => [ "https://${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}" ]
          ssl => true
          cacert => "/etc/pki/client/tls.crt"
          ssl_certificate_verification => false
          manage_template => false
          template_name => "ic_zbx_template"
          pipeline => "ic_zbx_pipeline"
          user => "${ELASTIC_USERNAME}"
          password => "${ELASTIC_PASSWORD}"
        }
      } else {
        elasticsearch {
          hosts => [ "https://${ELASTICSEARCH_HOST}:${ELASTICSEARCH_PORT}" ]
          ssl => true
          cacert => "/etc/pki/client/tls.crt"
          ssl_certificate_verification => false
          manage_template => false
          template_name => "ic_template"
          pipeline => "ic_pipeline"
          user => "${ELASTIC_USERNAME}"
          password => "${ELASTIC_PASSWORD}"
        }
      }
    }

serviceAccount:
  # Specifies whether a ServiceAccount should be created
  create: true
  # The name of the ServiceAccount to use.
  # If not set and create is true, a name is generated using the fullname template
  name:

## Additional arguments to pass to the Logstash entrypoint
# args:
  # - fizz
